Namespace(adaptive_weight=False, b=1000, benchmark_name='mountain_car', bs=2, data_attr='normal_52.0_59.0', data_bs=40, data_size=10000, dataset='thermostat', dataset_distribution='normal', debug=False, generate_all_dataset=False, l=128, lr=0.1, mode='DSE', module='linearrelu_no_act', n=5, nn_mode='all', num_components=10, num_epoch=10, only_data_loss=False, optimizer='direct', outside_trajectory_loss=True, perturbation_width=0.01, real_unsafe_value=True, save='True', sound_verify=False, stop_val=0.05, t_epoch=10, test_mode=False, test_portion=0.99, test_size=800, train_size=400, unsound_verify=False, use_smooth_kernel=True, verification_num_abstract_states=2, verification_num_components=500, verify_outside_trajectory_loss=True, w=0.5, width=0.01)
Target info: [[-0.8, 0.8], [0.5, 10000.0]], [0.1, 0.1],         [1.0, 0], ['all', 'last'], [0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1]
path_num_list: [50]path_sample_size: 50, safa_range_bound: 0.5
0-th Epochs Time: 2505.0759592056274
-----finish 0-th epoch-----, the batch loss: q: 0.24050329625606537, c: 0.05713086947798729
-----finish 0-th epoch-----, q: 2.2031023502349854, c: 0.10860748589038849
1-th Epochs Time: 2367.1092499494553
-----finish 1-th epoch-----, the batch loss: q: 0.23360686004161835, c: 0.05481952428817749
-----finish 1-th epoch-----, q: 2.1220390796661377, c: 0.13017837703227997
2-th Epochs Time: 2304.755799214045
-----finish 2-th epoch-----, the batch loss: q: 0.2302662432193756, c: 0.05318077281117439
-----finish 2-th epoch-----, q: 2.0794968605041504, c: 0.1244087666273117
3-th Epochs Time: 2242.073931157589
-----finish 3-th epoch-----, the batch loss: q: 0.2276713103055954, c: 0.061067141592502594
-----finish 3-th epoch-----, q: 2.051152229309082, c: 0.12721127271652222
4-th Epochs Time: 2204.788162612915
-----finish 4-th epoch-----, the batch loss: q: 0.22539715468883514, c: 0.05251175910234451
-----finish 4-th epoch-----, q: 2.028808116912842, c: 0.11814809590578079
5-th Epochs Time: 2168.1838081677756
-----finish 5-th epoch-----, the batch loss: q: 0.22487245500087738, c: 0.059644486755132675
-----finish 5-th epoch-----, q: 2.015089750289917, c: 0.12612749636173248
6-th Epochs Time: 2128.182392699378
-----finish 6-th epoch-----, the batch loss: q: 0.2235698252916336, c: 0.06142498925328255
-----finish 6-th epoch-----, q: 2.001415729522705, c: 0.1480039805173874
7-th Epochs Time: 2080.05326962471
-----finish 7-th epoch-----, the batch loss: q: 0.22233565151691437, c: 0.05394381284713745
-----finish 7-th epoch-----, q: 1.990280270576477, c: 0.11564090102910995
8-th Epochs Time: 2046.4079383214314
-----finish 8-th epoch-----, the batch loss: q: 0.22283104062080383, c: 0.06912314891815186
-----finish 8-th epoch-----, q: 1.986765742301941, c: 0.1479351967573166
9-th Epochs Time: 2015.1191504478454
-----finish 9-th epoch-----, the batch loss: q: 0.22410069406032562, c: 0.07241516560316086
-----finish 9-th epoch-----, q: 1.9862788915634155, c: 0.14033377170562744
One train: Optimization--20151.19262433052,10,2015.119262433052
