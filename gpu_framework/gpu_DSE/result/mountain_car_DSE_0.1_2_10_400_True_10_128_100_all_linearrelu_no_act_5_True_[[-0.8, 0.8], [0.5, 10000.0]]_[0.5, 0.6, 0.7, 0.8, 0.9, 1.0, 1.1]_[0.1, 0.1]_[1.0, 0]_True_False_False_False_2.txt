Namespace(adaptive_weight=False, b=100, benchmark_name='mountain_car', bs=2, data_attr='normal_52.0_59.0', data_bs=2, data_size=10000, dataset='thermostat', dataset_distribution='normal', debug=False, generate_all_dataset=False, l=128, lr=0.1, mode='DSE', module='linearrelu_no_act', n=5, nn_mode='all', num_components=10, num_epoch=10, only_data_loss=False, optimizer='direct', outside_trajectory_loss=True, perturbation_width=0.01, real_unsafe_value=True, save='True', sound_verify=False, stop_val=0.05, t_epoch=10, test_mode=False, test_portion=0.99, test_size=800, train_size=400, unsound_verify=False, use_smooth_kernel=True, verification_num_abstract_states=2, verification_num_components=500, verify_outside_trajectory_loss=True, w=0.5, width=0.01)
Target info: [[-0.8, 0.8], [0.5, 10000.0]], [0.1, 0.1],         [1.0, 0], ['all', 'last'], [0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1]
path_num_list: [50]path_sample_size: 50, safa_range_bound: 0.5
0-th Epochs Time: 2027.2607743740082
-----finish 0-th epoch-----, the batch loss: q: 0.19024653732776642, c: 0.061800409108400345
-----finish 0-th epoch-----, q: 41.38901138305664, c: 0.14104263484477997
1-th Epochs Time: 2190.748016476631
-----finish 1-th epoch-----, the batch loss: q: 0.1505805104970932, c: 0.07352074235677719
-----finish 1-th epoch-----, q: 34.687965393066406, c: 0.15766996145248413
2-th Epochs Time: 2213.8805916309357
-----finish 2-th epoch-----, the batch loss: q: 0.14078548550605774, c: 0.06483224034309387
-----finish 2-th epoch-----, q: 29.287277221679688, c: 0.1406322717666626
3-th Epochs Time: 1845.3901090025902
-----finish 3-th epoch-----, the batch loss: q: 0.12821133434772491, c: 0.037009067833423615
-----finish 3-th epoch-----, q: 5.806162357330322, c: 0.037009067833423615
TIMEOUT: avg epoch time > 2000s 
One train: Optimization--7381.566167116165,4,1845.3915417790413
0-th Epochs Time: 2041.202996969223
-----finish 0-th epoch-----, the batch loss: q: 0.20051181316375732, c: 0.06938981264829636
-----finish 0-th epoch-----, q: 42.02360534667969, c: 0.1417403370141983
1-th Epochs Time: 1978.2755726575851
-----finish 1-th epoch-----, the batch loss: q: 0.1724778115749359, c: 0.0736052617430687
-----finish 1-th epoch-----, q: 36.54942321777344, c: 0.15337105095386505
2-th Epochs Time: 1972.8746955394745
-----finish 2-th epoch-----, the batch loss: q: 0.14325448870658875, c: 0.0628717914223671
-----finish 2-th epoch-----, q: 31.213146209716797, c: 0.13921672105789185
3-th Epochs Time: 1909.1219176054
-----finish 3-th epoch-----, the batch loss: q: 0.1253613531589508, c: 0.07475124299526215
-----finish 3-th epoch-----, q: 27.5236873626709, c: 0.1465613842010498
4-th Epochs Time: 1748.2186408042908
-----finish 4-th epoch-----, the batch loss: q: 0.11548248678445816, c: 0.07911775261163712
-----finish 4-th epoch-----, q: 24.909730911254883, c: 0.1604839265346527
5-th Epochs Time: 1568.7512227694194
-----finish 5-th epoch-----, the batch loss: q: 0.1124638095498085, c: 0.07336878031492233
-----finish 5-th epoch-----, q: 22.949731826782227, c: 0.15409281849861145
6-th Epochs Time: 1477.1191414424352
-----finish 6-th epoch-----, the batch loss: q: 0.10358357429504395, c: 0.06210533529520035
-----finish 6-th epoch-----, q: 21.538084030151367, c: 0.1389952003955841
7-th Epochs Time: 1366.2718841135502
-----finish 7-th epoch-----, the batch loss: q: 0.06405551731586456, c: 0.0689658597111702
-----finish 7-th epoch-----, q: 13.123458862304688, c: 0.1551235318183899
8-th Epochs Time: 1279.0263267623054
-----finish 8-th epoch-----, the batch loss: q: 0.07243441790342331, c: 0.06778550893068314
-----finish 8-th epoch-----, q: 12.988325119018555, c: 0.14956142008304596
9-th Epochs Time: 1212.507750558853
-----finish 9-th epoch-----, the batch loss: q: 0.05579308420419693, c: 0.07241985946893692
-----finish 9-th epoch-----, q: 11.116913795471191, c: 0.16788744926452637
One train: Optimization--12125.079895734787,10,1212.5079895734787
0-th Epochs Time: 2175.9845066070557
-----finish 0-th epoch-----, the batch loss: q: 0.20894069969654083, c: 0.04765511676669121
-----finish 0-th epoch-----, q: 41.120487213134766, c: 0.11799590289592743
1-th Epochs Time: 1956.9671057462692
-----finish 1-th epoch-----, the batch loss: q: 0.16430045664310455, c: 0.06670506298542023
-----finish 1-th epoch-----, q: 36.05628204345703, c: 0.13016104698181152
2-th Epochs Time: 1883.6184357007344
-----finish 2-th epoch-----, the batch loss: q: 0.14273224771022797, c: 0.06984438747167587
-----finish 2-th epoch-----, q: 30.300729751586914, c: 0.12499096989631653
3-th Epochs Time: 1754.0981429219246
-----finish 3-th epoch-----, the batch loss: q: 0.12396174669265747, c: 0.0816226452589035
-----finish 3-th epoch-----, q: 26.705951690673828, c: 0.14677470922470093
TIMEOUT: avg epoch time > 2000s 
One train: Optimization--7016.400889635086,4,1754.1002224087715
path_sample_size: 50, safa_range_bound: 0.6
