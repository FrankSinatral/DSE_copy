Namespace(b=1000, benchmark_name='mountain_car', bs=2, data_attr='normal_-0.6_-0.4', data_size=10000, dataset='thermostat', dataset_distribution='normal', debug=False, l=100, lr=0.001, mode='DSE', module='linearrelu', n=5, nn_mode='all', num_components=10, num_epoch=10, optimizer='direct', perturbation_width=0.01, save='True', stop_val=0.05, t_epoch=10, test_mode=False, test_portion=0.99, test_size=200, train_size=400, use_smooth_kernel=True, verification_num_components=5000, w=0.5, width=0.01)
safe range: [100.0, 100.0]
path_num_list: [50]path_sample_size: 50, safe_range_upper_bound: 80.0
0-th Epochs Time: 831.2054023742676
-----finish 0-th epoch-----, the batch loss: q: 2.3062500953674316, c: -0.10000000149011612
-----finish 0-th epoch-----, q: 9.217500686645508, c: 2.22117018699646
1-th Epochs Time: 785.9203506708145
-----finish 1-th epoch-----, the batch loss: q: 2.2750000953674316, c: -0.10000000149011612
-----finish 1-th epoch-----, q: 11.487499237060547, c: -0.5
2-th Epochs Time: 775.8012477556864
-----finish 2-th epoch-----, the batch loss: q: 2.231250047683716, c: -0.10000000149011612
-----finish 2-th epoch-----, q: 11.050000190734863, c: -0.5
3-th Epochs Time: 772.1214842796326
-----finish 3-th epoch-----, the batch loss: q: 2.262500047683716, c: -0.10000000149011612
-----finish 3-th epoch-----, q: 11.25, c: -0.5
4-th Epochs Time: 771.4631410598755
-----finish 4-th epoch-----, the batch loss: q: 2.393749952316284, c: -0.10000000149011612
-----finish 4-th epoch-----, q: 11.412500381469727, c: -0.5
5-th Epochs Time: 807.2765876054764
-----finish 5-th epoch-----, the batch loss: q: 2.293750047683716, c: -0.10000000149011612
-----finish 5-th epoch-----, q: 11.193750381469727, c: -0.5
6-th Epochs Time: 833.1197509765625
-----finish 6-th epoch-----, the batch loss: q: 2.3500001430511475, c: -0.10000000149011612
-----finish 6-th epoch-----, q: 11.24375057220459, c: -0.5
7-th Epochs Time: 852.3821077644825
-----finish 7-th epoch-----, the batch loss: q: 2.262500047683716, c: -0.10000000149011612
-----finish 7-th epoch-----, q: 11.143750190734863, c: -0.5
8-th Epochs Time: 867.2618328730265
-----finish 8-th epoch-----, the batch loss: q: 2.3812501430511475, c: -0.10000000149011612
-----finish 8-th epoch-----, q: 11.381250381469727, c: -0.5
9-th Epochs Time: 879.4455731868744
-----finish 9-th epoch-----, the batch loss: q: 2.293750047683716, c: -0.10000000149011612
-----finish 9-th epoch-----, q: 11.331250190734863, c: -0.5
One train: Optimization--8794.462226390839,10,879.4462226390839
