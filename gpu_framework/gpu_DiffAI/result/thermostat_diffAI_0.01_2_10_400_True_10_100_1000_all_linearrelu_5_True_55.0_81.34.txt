Namespace(b=1000, benchmark_name='thermostat', bs=2, data_attr='normal_55.0_62.0', data_size=10000, l=100, lr=0.01, module='linearrelu', n=5, nn_mode='all', num_components=10, num_epoch=10, optimizer='direct', save='True', stop_val=0.05, t_epoch=10, test_mode=False, test_portion=0.99, test_size=20000, train_size=400, use_smooth_kernel=True, w=0.5, width=0.3)
safe range: [55.0, 81.34]
path_num_list: [250]path_sample_size: 250
0-th Epochs Time: 300.87641429901123
-----finish 0-th epoch-----, the batch loss: q: 76.4024429321289, c: 99.3055648803711
-----finish 0-th epoch-----, the epoch loss: q: 581.4046020507812, c: 718.1987915039062
1-th Epochs Time: 308.4691399335861
-----finish 1-th epoch-----, the batch loss: q: 6.685438632965088, c: 26.383764266967773
-----finish 1-th epoch-----, the epoch loss: q: 643.2660522460938, c: 407.37969970703125
2-th Epochs Time: 306.29755036036175
-----finish 2-th epoch-----, the batch loss: q: 6.685438632965088, c: 0.020810185000300407
-----finish 2-th epoch-----, the epoch loss: q: 413.8326110839844, c: 35.090065002441406
3-th Epochs Time: 305.0207510590553
-----finish 3-th epoch-----, the batch loss: q: 6.685438632965088, c: 0.020810185000300407
-----finish 3-th epoch-----, the epoch loss: q: 41.33262634277344, c: 5.098397731781006
4-th Epochs Time: 304.23566060066224
-----finish 4-th epoch-----, the batch loss: q: 6.685438632965088, c: 0.020810185000300407
-----finish 4-th epoch-----, the epoch loss: q: 41.33262634277344, c: 5.098397731781006
5-th Epochs Time: 303.7653546333313
-----finish 5-th epoch-----, the batch loss: q: 6.685438632965088, c: 0.020810185000300407
-----finish 5-th epoch-----, the epoch loss: q: 41.33262634277344, c: 5.098397731781006
6-th Epochs Time: 303.4437535490309
-----finish 6-th epoch-----, the batch loss: q: 6.685438632965088, c: 0.020810185000300407
-----finish 6-th epoch-----, the epoch loss: q: 41.33262634277344, c: 5.098397731781006
7-th Epochs Time: 303.18685710430145
-----finish 7-th epoch-----, the batch loss: q: 6.685438632965088, c: 0.020810185000300407
-----finish 7-th epoch-----, the epoch loss: q: 41.33262634277344, c: 5.098397731781006
8-th Epochs Time: 302.9946596092648
-----finish 8-th epoch-----, the batch loss: q: 6.685438632965088, c: 0.020810185000300407
-----finish 8-th epoch-----, the epoch loss: q: 41.33262634277344, c: 5.098397731781006
9-th Epochs Time: 302.8444865226746
-----finish 9-th epoch-----, the batch loss: q: 6.685438632965088, c: 0.020810185000300407
-----finish 9-th epoch-----, the epoch loss: q: 41.33262634277344, c: 5.098397731781006
One train: Optimization--3028.446056842804,10,302.8446056842804
